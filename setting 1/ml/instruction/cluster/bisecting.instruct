Implement the bisecting k-means clustering algorithm with python, numpy and scipy.  

Bisecting k-means is a clustering algorithm that is a variant of the standard k-means algorithm. It is particularly useful for creating a hierarchical decomposition of the data set. Unlike the traditional k-means that partitions the entire dataset into k clusters simultaneously, bisecting k-means repeatedly applies k-means with k=2 (bisecting step) on selected clusters to split them until the desired number of clusters is reached. This method often leads to improved cluster quality in terms of intra-cluster similarity.

### Algorithmic Flow of Bisecting k-Means

1. **Initialization**:
   - Start with all data points in a single cluster.

2. **Bisecting Step**:
   - Select a cluster to split. Initially, this is the cluster containing all data points. In later iterations, selection criteria might be the size of the cluster, the sum of squared errors (SSE), or other heuristics.
   - Apply the standard k-means clustering algorithm with k=2 to the selected cluster. This divides the cluster into two subclusters.

3. **Iteration**:
   - Evaluate the results of the bisecting step. Typically, the evaluation is based on a measure like SSE, which is the sum of the squared distances between each data point and its nearest cluster center:
     \[
     SSE = \sum_{i=1}^{n} \min_{\mu_j \in C} \|x_i - \mu_j\|^2
     \]
     where \( x_i \) are data points, \( \mu_j \) are the centroids of clusters \( C \), and \( n \) is the number of data points.
   - Decide whether to repeat the bisecting step on one of the two new clusters or on a different existing cluster.

4. **Repetition**:
   - Repeat the bisecting step until the desired number of clusters is achieved.

### Mathematical Formulas and Derivations

The key mathematical component in bisecting k-means is the calculation of the SSE, which helps in evaluating the compactness of the clusters formed. The SSE for a single cluster is calculated as:
\[
SSE = \sum_{x \in S} \|x - \mu\|^2
\]
where \( S \) is the set of data points in the cluster, \( x \) is a data point in \( S \), and \( \mu \) is the centroid of \( S \). The centroid is the average of all points in \( S \):
\[
\mu = \frac{1}{|S|} \sum_{x \in S} x
\]

During each bisecting step, the algorithm chooses the cluster with the highest SSE to split, aiming to maximize the decrease in SSE. The goal is to find two subclusters such that the sum of their SSEs is minimized.

The module should be named GPTBisectingKmeans.  
The init function should include the following parameters:
n_clusters: The number of clusters to form as well as the number of centroids to generate.
The module must contain a fit_predict function.  
The fit_predict function accepts X as input and return labels where  
X: X is the features of the data, which is a numpy array and it's shape is [N, d]. N is the number of the train data and d is the dimension.  
labels: A numpy array of shape (n_samples,) containing the index of the cluster each sample belongs to.  
You should just return the code for the module, don't return anything else.