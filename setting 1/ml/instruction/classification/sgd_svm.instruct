Implement the svm classifier based on the SGD algorithm with python, numpy and scipy. It can handle multi-class classification problems. It uses the Gaussian kernel function. The loss should be hinge loss.

The Gaussian kernel, also known as the Radial Basis Function (RBF) kernel, is defined as:

\[ K(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right) \]

where \( x_i \) and \( x_j \) are data points, and \( \sigma \) is a parameter that determines the spread of the kernel.

### Hinge Loss

The hinge loss is used to measure the error of the SVM classifier. It is defined as:

\[ L(y_i, f(x_i)) = \max(0, 1 - y_i \cdot f(x_i)) \]

where \( y_i \) is the true label of the data point \( x_i \), and \( f(x_i) \) is the predicted output.

### Algorithmic Flow with SGD

1. **Initialization**: Start with an initial weight vector \( w \) and bias \( b \). These can be initialized to zero or small random values.

2. **Kernel Transformation**: Transform the input data using the Gaussian kernel to map it into a higher-dimensional space.

3. **Iterative Optimization**: Use SGD to minimize the hinge loss function. For each training sample \( (x_i, y_i) \):

   - Compute the decision function: 
     \[ f(x_i) = \sum_{j=1}^{n} \alpha_j y_j K(x_j, x_i) + b \]

   - Calculate the hinge loss:
     \[ L(y_i, f(x_i)) = \max(0, 1 - y_i \cdot f(x_i)) \]

   - Update the weights and bias if the sample is misclassified (i.e., if \( y_i \cdot f(x_i) < 1 \)):
     \[
     w = w - \eta \left( \frac{\partial L}{\partial w} \right) = w - \eta \left( -y_i x_i \right)
     \]
     \[
     b = b - \eta \left( \frac{\partial L}{\partial b} \right) = b - \eta \left( -y_i \right)
     \]
     where \( \eta \) is the learning rate.

The module should be named GPTSgdSvm.  
The module must contain a fit function and a predict function.  
The fit function accepts X_train, y_train as input and return None where  
X_train: the features of the train data, which is a numpy array, and the shape of X_train is [N, d]. N is the number of the train data and d is the dimension.  
y_train: the labels pf the train data,which is a numpy array.  
The predict function accepts X_test as input and return predictions where  
X_test: the features of the test data, which is a numpy array, and the shape of X_train is [N, d]. N is the number of the test data and d is the dimension.  
predctions: the predicted classes for X_test, which is a numpy arrary.  
You should just return the code for the module, don't return anything else.