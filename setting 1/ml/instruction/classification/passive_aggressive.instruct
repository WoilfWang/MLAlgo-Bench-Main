Implement the Passive Aggressive Classifier with python, numpy and scipy. It can handle multi-class classification problems. 

The core idea behind the Passive Aggressive Classifier is to adjust the model only when it makes a mistake or when the prediction is not confident enough. Unlike other algorithms that might update the model for every instance, the Passive Aggressive approach updates only when necessary, making it efficient for large-scale and streaming data.

### Algorithmic Flow

1. **Initialization**: Start with an initial weight vector \( \mathbf{w} \), often initialized to zero.

2. **Iterate over each instance**: For each training instance \( (\mathbf{x}_i, y_i) \), where \( \mathbf{x}_i \) is the feature vector and \( y_i \) is the true label (typically \( +1 \) or \( -1 \)):

   - **Prediction**: Compute the prediction \( \hat{y}_i \) using the current weight vector:
     \[
     \hat{y}_i = \text{sign}(\mathbf{w} \cdot \mathbf{x}_i)
     \]

   - **Calculate Loss**: If the prediction is incorrect or not confident enough, calculate the hinge loss:
     \[
     L(\mathbf{w}; \mathbf{x}_i, y_i) = \max(0, 1 - y_i (\mathbf{w} \cdot \mathbf{x}_i))
     \]

   - **Update Rule**: If \( L > 0 \), update the weight vector \( \mathbf{w} \) using:
     \[
     \mathbf{w} \leftarrow \mathbf{w} + \tau_i y_i \mathbf{x}_i
     \]
     where \( \tau_i \) is the step size, calculated as:
     \[
     \tau_i = \frac{L(\mathbf{w}; \mathbf{x}_i, y_i)}{\|\mathbf{x}_i\|^2}
     \]
     This step size ensures that the update is aggressive enough to correct the mistake but not too large to destabilize the model.

3. **Repeat**: Continue this process for each instance in the dataset or stream.

### Mathematical Derivation

The update rule is derived from the optimization problem that aims to minimize the hinge loss while keeping the update as small as possible. Formally, the optimization problem is:

\[
\min_{\mathbf{w}} \frac{1}{2} \|\mathbf{w} - \mathbf{w}_{\text{old}}\|^2 + C \cdot L(\mathbf{w}; \mathbf{x}_i, y_i)
\]

where \( C \) is a regularization parameter that controls the trade-off between making updates and keeping the model stable. Solving this optimization problem leads to the update rule and step size mentioned above.

The module should be named GPTPassiveAggressive.  
The init funtion should include the following parameters:
C: Maximum step size (regularization).
The module must contain a fit function and a predict function.  
The fit function accepts X_train, y_train as input and return None where  
X_train: the features of the train data, which is a numpy array, and the shape of X_train is [N, d]. N is the number of the train data and d is the dimension.  
y_train: the labels pf the train data,which is a numpy array.  
The predict function accepts X_test as input and return predictions where  
X_test: the features of the test data, which is a numpy array, and the shape of X_train is [N, d]. N is the number of the test data and d is the dimension.  
predctions: the predicted classes for X_test, which is a numpy arrary.  
You should just return the code for the module, don't return anything else.