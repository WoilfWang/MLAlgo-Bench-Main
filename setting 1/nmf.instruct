Given an instruction about a machine learning algorithm, implement the relevant code based on this instruction.
You should implement the algorithm by using Python, Numpy or Scipy from scratch. You can't use any functions or classes from scikit-learn.
You only need to implement the algorithm module, and you don't need to generate test cases.
You should create as many sub-functions or sub-classes as possible to help you implement the entire algorithm.
Just output the code of the algorithm, don't output anything else.

Instruction:

Implement the NMF algorithm for dimensionality reduction with python, numpy and scipy.
Non-Negative Matrix Factorization. Find two non-negative matrices, i.e. matrices with all non-negative elements, (W, H) whose product approximates the non-negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction. The objective function is: 
L(W, H) &= 0.5 * ||X - WH||_{loss}^2
&+ alpha\\_W * l1\\_ratio * n\\_features * ||vec(W)||_1
&+ alpha\\_H * l1\\_ratio * n\\_samples * ||vec(H)||_1
&+ 0.5 * alpha\\_W * (1 - l1\\_ratio) * n\\_features * ||W||_{Fro}^2
&+ 0.5 * alpha\\_H * (1 - l1\\_ratio) * n\\_samples * ||H||_{Fro}^2
Where:
:math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (Frobenius norm)
:math:`||vec(A)||_1 = \\sum_{i,j} abs(A_{ij})` (Elementwise L1 norm)
The generic norm :math:`||X - WH||_{loss}` may represent the Frobenius norm or another supported beta-divergence loss. The choice between options is controlled by the `beta_loss` parameter. The regularization terms are scaled by `n_features` for `W` and by `n_samples` for `H` to keep their impact balanced with respect to one another and to the data fit term as independent as possible of the size `n_samples` of the training set. The objective function is minimized with an alternating minimization of W and H. Note that the transformed data is named W and the components matrix is named H. In the NMF literature, the naming convention is usually the opposite since the data matrix X is transposed.
The module should be named GPTNMF.
The init function should include the following parameters:
n_components: Number of reducted components.
The module must contain a fit_transform function.
The fit_transform function accepts X as input and return reduced_X where
X: X is the features of the data, which is a numpy array and it's shape is [N, d]. N is the number of the train data and d is the dimension.
reduced_X: reduced_X is the reduced features after dimensionality reduction. The shape should be [N, low_d], where N is the num of the data and low_d is the reduced dimension.
You should just return the code for the module, don't return anything else.